{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Latent Dirichlet Allocation (LDA) Training",
   "id": "5fe84f47a9f8a9d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependencies",
   "id": "46477f52726e26a1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import datetime\n",
    "from gensim import corpora, models\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.topic_diversity import topic_diversity\n",
    "import pyLDAvis.gensim_models\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Dataset",
   "id": "60d3947cac0a857f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../data/processed/20250516_1955_clean_merged_tweets.csv\")\n",
    "df.info()"
   ],
   "id": "152f85c0e72d2271",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation / Config",
   "id": "ec042e21302bff20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CONFIGURATION FOR SAVING\n",
    "model_name = 'LDA'\n",
    "\n",
    "# Get today's date in YYYYMMDD format\n",
    "date_today = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Saved dir path\n",
    "results_dir = f\"../results/{date_today}_{model_name}\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Set Top-N of words\n",
    "TOP_DIVERSITY_WORDS_N = 30\n",
    "TOP_COHERENCE_WORDS_N = 10\n",
    "\n",
    "# Tokenize\n",
    "df['tokenized_content'] = df['final_text'].apply(lambda x: str(x).split())\n",
    "texts = df['tokenized_content'].tolist()"
   ],
   "id": "f77c59d1fb5adacb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter Filter Extremes (no_below, no_above, keep_n)",
   "id": "ab7600fc389f1be3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Parameter grid\n",
    "no_below_values = [2, 5, 10, 50, 100]\n",
    "no_above_values = [0.5, 0.7, 0.9, 0.95]\n",
    "keep_n_values = [30000, 50000, 70000, 90000]\n",
    "\n",
    "\n",
    "# Fixed Model Settings\n",
    "NUM_TOPICS = 16\n",
    "PASSES = 10\n",
    "WORKERS = 10\n",
    "\n",
    "# Store results\n",
    "filter_extremes_hyperparameter = []\n",
    "best_coherence = -1\n",
    "best_filter_extremes = None\n",
    "\n",
    "# Start Grid Search\n",
    "for no_below, no_above, keep_n in itertools.product(no_below_values, no_above_values, keep_n_values):\n",
    "    # Build dictionary\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    dictionary.filter_extremes(no_below=no_below, no_above=no_above, keep_n=keep_n)\n",
    "\n",
    "    # Create corpus\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "\n",
    "    # Train LDA model\n",
    "    lda_model = models.LdaMulticore(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=NUM_TOPICS,\n",
    "        passes=PASSES,\n",
    "        workers=WORKERS,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Compute coherence\n",
    "    coherence_model = models.CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v', topn=TOP_COHERENCE_WORDS_N)\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "    # Store result\n",
    "    filter_extremes_hyperparameter.append({\n",
    "        \"no_below\": no_below,\n",
    "        \"no_above\": no_above,\n",
    "        \"keep_n\": keep_n,\n",
    "        \"coherence\": coherence_score,\n",
    "        \"dictionary_size\": len(dictionary),\n",
    "        \"num_topics\": NUM_TOPICS,\n",
    "    })\n",
    "\n",
    "    print(f\"no_below={no_below}, no_above={no_above}, keep_n={keep_n}, dict_size={len(dictionary)}  coherence={coherence_score:.4f}\")\n",
    "\n",
    "    # Track best\n",
    "    if coherence_score > best_coherence:\n",
    "        best_coherence = coherence_score\n",
    "        best_filter_extremes = (no_below, no_above, keep_n)\n",
    "\n",
    "\n",
    "# Summary\n",
    "print(\"\\nBest Filtering Parameters:\")\n",
    "print(f\"Best no_below: {best_filter_extremes[0]}, Best no_above: {best_filter_extremes[1]}, Best keep_n: {best_filter_extremes[2]}, Best Coherence Score: {best_coherence:.4f}\")\n",
    "\n",
    "# Save Results\n",
    "df_filter_extremes_hyperparameter = pd.DataFrame(filter_extremes_hyperparameter)\n",
    "df_filter_extremes_hyperparameter.to_csv(os.path.join(results_dir, f\"filter_extremes_hyperparameter_{date_today}.csv\"), index=False)\n",
    "print(f\"Filter extremes results saved in: {results_dir} \")"
   ],
   "id": "bd1a5b28abcbc605",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create Dict Based on Best Filter Params",
   "id": "f20ffaab4846f9e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load or define the best parameters\n",
    "BEST_NO_BELOW = best_filter_extremes[0]\n",
    "BEST_NO_ABOVE = best_filter_extremes[1]\n",
    "BEST_KEEP_N = best_filter_extremes[2]\n",
    "\n",
    "# Create dictionary and corpus with best filtering\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=BEST_NO_BELOW, no_above=BEST_NO_ABOVE, keep_n=BEST_KEEP_N)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in texts]"
   ],
   "id": "8a1f746c5c8c5504",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyperparameter Num Topics (num_topics)",
   "id": "464f7fd8899707e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define num_topics range to test\n",
    "num_topics_range = list(range(2, 27))\n",
    "\n",
    "# Fixed settings\n",
    "PASSES = 10\n",
    "WORKERS = 10\n",
    "\n",
    "# Store results\n",
    "topic_num_tuning_results = []\n",
    "best_coherence = -1\n",
    "best_num_topics = None\n",
    "\n",
    "# Grid search over num_topics\n",
    "for num_topics in num_topics_range:\n",
    "    # Train model\n",
    "    lda_model = models.LdaMulticore(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=num_topics,\n",
    "        passes=PASSES,\n",
    "        workers=WORKERS,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Compute coherence\n",
    "    coherence_model = models.CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v', topn=TOP_COHERENCE_WORDS_N)\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "    # Store results\n",
    "    topic_num_tuning_results.append({\n",
    "        \"num_topics\": num_topics,\n",
    "        \"coherence\": coherence_score,\n",
    "        \"no_below\": BEST_NO_BELOW,\n",
    "        \"no_above\": BEST_NO_ABOVE,\n",
    "        \"keep_n\": BEST_KEEP_N,\n",
    "        \"dictionary_size\": len(dictionary)\n",
    "    })\n",
    "\n",
    "    print(f\" num_topics={num_topics} coherence={coherence_score:.4f}\")\n",
    "\n",
    "    if coherence_score > best_coherence:\n",
    "        best_coherence = coherence_score\n",
    "        best_num_topics = num_topics\n",
    "\n",
    "# Summary\n",
    "print(\"\\nBest Number of Topics:\")\n",
    "print(f\"Best num_topics: {best_num_topics}, Best Coherence Score: {best_coherence:.4f}\")\n",
    "\n",
    "# Save results\n",
    "df_topic_num_tuning = pd.DataFrame(topic_num_tuning_results)\n",
    "df_topic_num_tuning.to_csv(os.path.join(results_dir, f\"num_topics_hyperparameter_{date_today}.csv\"), index=False)\n",
    "print(f\"Hyperparameter topics results saved in: {results_dir} \")"
   ],
   "id": "6fb71e3579652262",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize num_topics Grid Search",
   "id": "950f62e3972a9436"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(df_topic_num_tuning[\"num_topics\"], df_topic_num_tuning[\"coherence\"], marker='o')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score (c_v)\")\n",
    "plt.title(\"LDA Topic Coherence vs Number of Topics\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "17642bb54fdf0fd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyperparameter Best Params (alpha, eta)",
   "id": "18680443f2b75f54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BEST_NUM_TOPICS = best_num_topics\n",
    "\n",
    "# Parameter grid\n",
    "alpha_values = ['symmetric', 'asymmetric', 0.01, 0.1, 0.5]\n",
    "eta_values   = ['symmetric', 0.01, 0.1, 0.5]\n",
    "\n",
    "PASSES = 10\n",
    "WORKERS = 10\n",
    "\n",
    "# Store results\n",
    "alpha_eta_tuning_results = []\n",
    "best_coherence = -1\n",
    "best_alpha_eta = None\n",
    "\n",
    "# Grid search over alpha and eta\n",
    "for alpha, eta in itertools.product(alpha_values, eta_values):\n",
    "    # Train model\n",
    "    lda_model = models.LdaMulticore(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=BEST_NUM_TOPICS,\n",
    "        passes=PASSES,\n",
    "        workers=WORKERS,\n",
    "        alpha=alpha,\n",
    "        eta=eta,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Coherence score\n",
    "    coherence_model = models.CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v', topn=TOP_COHERENCE_WORDS_N)\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "    # Store results\n",
    "    alpha_eta_tuning_results.append({\n",
    "        \"alpha\": alpha,\n",
    "        \"eta\": eta,\n",
    "        \"coherence\": coherence_score,\n",
    "        \"no_below\": BEST_NO_BELOW,\n",
    "        \"no_above\": BEST_NO_ABOVE,\n",
    "        \"keep_n\": BEST_KEEP_N,\n",
    "        \"num_topics\": BEST_NUM_TOPICS,\n",
    "        \"dictionary_size\": len(dictionary)\n",
    "    })\n",
    "\n",
    "    print(f\" alpha={alpha}, eta={eta} coherence={coherence_score:.4f}\")\n",
    "\n",
    "    if coherence_score > best_coherence:\n",
    "        best_coherence = coherence_score\n",
    "        best_alpha_eta = (alpha, eta)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nBest Alpha/Eta Combination:\")\n",
    "print(f\"Best alpha: {best_alpha_eta[0]}, Best eta: {best_alpha_eta[1]}, Best Coherence Score: {best_coherence:.4f}\")\n",
    "\n",
    "# Save results\n",
    "df_alpha_eta_tuning = pd.DataFrame(alpha_eta_tuning_results)\n",
    "df_alpha_eta_tuning.to_csv(os.path.join(results_dir, f\"alpha_eta_hyperparameter_{date_today}.csv\"), index=False)\n",
    "print(f\"Filter extremes results saved in: {results_dir} \")"
   ],
   "id": "f545eba08821657f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Final Model",
   "id": "5f85c58b7e2db02f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BEST_NO_BELOW = best_filter_extremes[0]\n",
    "BEST_NO_ABOVE = best_filter_extremes[1]\n",
    "BEST_KEEP_N = best_filter_extremes[2]\n",
    "BEST_NUM_TOPICS = best_num_topics\n",
    "BEST_ALPHA = best_alpha_eta[0]\n",
    "BEST_ETA = best_alpha_eta[1]\n",
    "PASSES = 100\n",
    "WORKERS = 10\n",
    "\n",
    "#  Train final LDA model\n",
    "lda_model = models.LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=BEST_NUM_TOPICS,\n",
    "    passes=PASSES,\n",
    "    workers=WORKERS,\n",
    "    alpha=BEST_ALPHA,\n",
    "    eta=BEST_ETA,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#  Compute coherence score\n",
    "coherence_model = models.CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v', topn=TOP_COHERENCE_WORDS_N)\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "print(f\"ðŸŽ¯ Final model coherence (c_v): {coherence_score:.4f}\")\n",
    "\n",
    "#  Save model and artifacts\n",
    "lda_model.save(os.path.join(results_dir, f\"lda_model_{date_today}.gensim\"))\n",
    "dictionary.save(os.path.join(results_dir, f\"lda_dictionary_{date_today}.dict\"))\n",
    "corpora.MmCorpus.serialize(os.path.join(results_dir, f\"lda_corpus_{date_today}.mm\"), corpus)\n",
    "\n",
    "#  Save topic-word distributions to CSV\n",
    "topics = lda_model.show_topics(num_topics=BEST_NUM_TOPICS, num_words=TOP_DIVERSITY_WORDS_N, formatted=False)\n",
    "topic_word_list = []\n",
    "for topic_num, topic_words in topics:\n",
    "    for word, weight in topic_words:\n",
    "        topic_word_list.append({\n",
    "            \"topic\": topic_num,\n",
    "            \"word\": word,\n",
    "            \"weight\": weight\n",
    "        })\n",
    "\n",
    "df_topics = pd.DataFrame(topic_word_list)\n",
    "df_topics.to_csv(os.path.join(results_dir, f\"lda_topic_word_distributions_{date_today}.csv\"), index=False)\n",
    "\n",
    "#  Save document-topic distributions (optional)\n",
    "doc_topics = []\n",
    "for i, doc_bow in enumerate(corpus):\n",
    "    topic_dist = lda_model.get_document_topics(doc_bow, minimum_probability=0.0)\n",
    "    row = {\"doc_id\": i}\n",
    "    row.update({f\"topic_{t[0]}\": t[1] for t in topic_dist})\n",
    "    doc_topics.append(row)\n",
    "\n",
    "df_doc_topics = pd.DataFrame(doc_topics)\n",
    "df_doc_topics.to_csv(os.path.join(results_dir, f\"lda_document_topic_distributions_{date_today}.csv\"), index=False)\n",
    "\n",
    "#  Save final summary\n",
    "summary = {\n",
    "    \"no_below\": BEST_NO_BELOW,\n",
    "    \"no_above\": BEST_NO_ABOVE,\n",
    "    \"keep_n\": BEST_KEEP_N,\n",
    "    \"num_topics\": BEST_NUM_TOPICS,\n",
    "    \"alpha\": BEST_ALPHA,\n",
    "    \"eta\": BEST_ETA,\n",
    "    \"passes\": PASSES,\n",
    "    \"coherence_score\": coherence_score,\n",
    "    \"dictionary_size\": len(dictionary),\n",
    "    \"num_documents\": len(corpus),\n",
    "}\n",
    "\n",
    "# Diversity Scores\n",
    "top_n_values = [5, 10, 20, 30]\n",
    "diversity_score_results = []\n",
    "for top_n in top_n_values:\n",
    "    diversity_score = topic_diversity(lda_model, top_n=top_n, model_type='lda')\n",
    "    diversity_score_results.append({\"top_n\": top_n, \"topic_diversity\": diversity_score})\n",
    "    print(f\"top_n: {top_n} topic_diversity: {diversity_score}\")\n",
    "\n",
    "df_diversity = pd.DataFrame(diversity_score_results)\n",
    "df_diversity.to_csv(os.path.join(results_dir, f\"topic_diversity_scores_{date_today}.csv\"), index=False)\n",
    "\n",
    "for row in diversity_score_results:\n",
    "    summary[f\"diversity_score_top{row['top_n']}\"] = row[\"topic_diversity\"]\n",
    "\n",
    "# Save Summary\n",
    "pd.DataFrame([summary]).to_csv(os.path.join(results_dir, f\"lda_model_summary_{date_today}.csv\"), index=False)\n",
    "\n",
    "# Prepare the visualization data\n",
    "lda_vis_data = pyLDAvis.gensim_models.prepare(\n",
    "    topic_model=lda_model,\n",
    "    corpus=corpus,\n",
    "    dictionary=dictionary,\n",
    "    sort_topics=False\n",
    ")\n",
    "\n",
    "# Export as HTML\n",
    "pyLDAvis.save_html(lda_vis_data, os.path.join(results_dir, f\"lda_pyladavis_visualization_{date_today}.html\"))\n",
    "\n",
    "print(f\" Final model, topics, and summaries saved to: {results_dir}\")"
   ],
   "id": "aee758e99db881cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### View Top-30 Words per Topic",
   "id": "1f30b94d68b2c312"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get top words from the model\n",
    "topics = lda_model.show_topics(num_topics=BEST_NUM_TOPICS, num_words=TOP_DIVERSITY_WORDS_N, formatted=False)\n",
    "\n",
    "# Build structured list\n",
    "topic_word_data = []\n",
    "for topic_num, word_list in topics:\n",
    "    for rank, (word, weight) in enumerate(word_list, start=1):\n",
    "        topic_word_data.append({\n",
    "            \"topic\": topic_num,\n",
    "            \"word_rank\": rank,\n",
    "            \"word\": word,\n",
    "            \"weight\": weight\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_topic_words = pd.DataFrame(topic_word_data)\n",
    "\n",
    "# Save to CSV\n",
    "topic_words_filename = os.path.join(results_dir, f\"lda_top{TOP_DIVERSITY_WORDS_N}_words_per_topic_{date_today}.csv\")\n",
    "df_topic_words.to_csv(topic_words_filename, index=False)\n",
    "\n",
    "print(f\"Top {TOP_DIVERSITY_WORDS_N} words per topic saved to: {topic_words_filename}\")\n",
    "\n",
    "# Sample 30 Words per Topic\n",
    "print(f\"\\nTop {TOP_DIVERSITY_WORDS_N} Words per Topic:\")\n",
    "for topic_num, word_list in topics:\n",
    "    words_only = [word for word, weight in word_list]\n",
    "    print(f\"Topic {topic_num}: {', '.join(words_only)}\")"
   ],
   "id": "b2985d98fccb436",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
