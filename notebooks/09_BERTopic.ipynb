{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BERTopic Training",
   "id": "456101da8dde4348"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependencies",
   "id": "5af9ab098150eea4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "from gensim import corpora, models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import logging\n",
    "import itertools\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from src.utils.topic_diversity import topic_diversity\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk_data_path = \"../data/libs/nltk_data\"\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "logging.disable(logging.CRITICAL)\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "9c16dfc3c4418eee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Dataset",
   "id": "be7c9378108a9711"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../data/processed/20250515_1207_minimal_clean_merged_tweets.csv\")\n",
    "df.info()"
   ],
   "id": "317d882f2ecb3b72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparation / Config",
   "id": "16e0be8296cdf399"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CONFIGURATION FOR SAVING\n",
    "model_name = 'BERTOPIC'\n",
    "\n",
    "# Get today's date in YYYYMMDD format\n",
    "date_today = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Saved dir path\n",
    "results_dir = f\"../results/{date_today}_{model_name}\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "TOP_DIVERSITY_WORDS_N = 30\n",
    "TOP_COHERENCE_WORDS_N = 10\n",
    "\n",
    "# If should need Sampling\n",
    "SAMPLE_SIZE = 400000\n",
    "df_sample = df.sample(n=SAMPLE_SIZE, random_state=42).copy()\n",
    "documents = df_sample['final_text'].astype(str).tolist()\n",
    "print(f\"Sampled {len(df_sample)} rows from full dataset.\")\n",
    "\n",
    "# Full dataset\n",
    "# documents = df['final_text'].astype(str).tolist()\n",
    "# print(f\"{len(df)} rows from full dataset.\")\n",
    "\n",
    "# Tokenize\n",
    "tokenized_texts = [str(doc).split() for doc in documents]\n",
    "dictionary = corpora.Dictionary(tokenized_texts)"
   ],
   "id": "5731c4ba6a16108c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter Embedding Models",
   "id": "bf18a2e8a72c4fd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define search ranges\n",
    "embedding_models = [\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'paraphrase-MiniLM-L12-v2',\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'paraphrase-MPNet-base-v2'\n",
    "]\n",
    "\n",
    "# Store results\n",
    "embedding_model_results = []\n",
    "best_coherence = -1\n",
    "best_embedding_model = None\n",
    "\n",
    "# Run grid search for embedding model\n",
    "for model_name in embedding_models:\n",
    "    print(f\"\\nTesting embedding model: {model_name}\")\n",
    "\n",
    "    embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Initialize BERTopic with this embedding\n",
    "    topic_model = BERTopic(embedding_model=embedding_model, verbose=False)\n",
    "\n",
    "    topics, probs = topic_model.fit_transform(documents)\n",
    "    topic_words = topic_model.get_topics()\n",
    "\n",
    "    # Extract top_n words per topic\n",
    "    topic_words_list = [\n",
    "        [word for word, _ in topic_words[topic_id]]\n",
    "        for topic_id in topic_words if topic_id != -1  # ignore unclusterd for now\n",
    "    ]\n",
    "\n",
    "    # Compute Coherence\n",
    "    coherence_model = models.CoherenceModel(\n",
    "        topics=topic_words_list,\n",
    "        texts=tokenized_texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v',\n",
    "        topn=TOP_COHERENCE_WORDS_N,\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "    # Topic Stats\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    num_topics = len(topic_info[topic_info.Topic != -1])\n",
    "    avg_topic_size = topic_info[topic_info.Topic != -1]['Count'].mean()\n",
    "\n",
    "    # Store results\n",
    "    embedding_model_results.append({\n",
    "        \"embedding_model\": model_name,\n",
    "        \"num_topics\": num_topics,\n",
    "        \"avg_topic_size\": avg_topic_size,\n",
    "        \"coherence_c_v\": coherence_score\n",
    "    })\n",
    "\n",
    "    print(f\"embedding_model={model_name}, num_topics={num_topics}, avg_topic_size={avg_topic_size:.2f} coherence={coherence_score:.4f}\")\n",
    "\n",
    "    # Track best\n",
    "    if coherence_score > best_coherence:\n",
    "        best_coherence = coherence_score\n",
    "        best_embedding_model = model_name\n",
    "\n",
    "# Summary\n",
    "print(\"\\nBest Embedding Model:\")\n",
    "print(f\"Best Embedding Model: {best_embedding_model}\")\n",
    "\n",
    "# Save Results\n",
    "df_embedding_model_hyperparameter = pd.DataFrame(embedding_model_results)\n",
    "df_embedding_model_hyperparameter.to_csv(os.path.join(results_dir, f\"embedding_model_hyperparameter_{date_today}.csv\"), index=False)"
   ],
   "id": "233ee5e2465c9add",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter Vectorizer",
   "id": "edb3dadea3c65fac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BEST_EMBEDDING = best_embedding_model\n",
    "embedding_model = SentenceTransformer(BEST_EMBEDDING)\n",
    "\n",
    "# Prepare stopwords\n",
    "stopwords_list = set(stopwords.words(\"english\"))\n",
    "custom_stopwords = list(stopwords_list.union({\n",
    "     \"actually\", \"ago\", \"agree\", \"also\", \"answer\", \"anyone\", \"around\", \"article\", \"ask\", \"away\", \"back\", \"bad\", \"bit\", \"could\", \"come\", \"covid\", \"covid-19\", \"covid_19\", \"day\", \"damn\", \"disagree\", \"due\", \"else\", \"ever\", \"everyone\", \"example\", \"finally\", \"find\", \"follow\", \"fuck\", \"get\", \"give\", \"go\", \"good\", \"hah\", \"haha\", \"happen\", \"hear\", \"hell\", \"info\", \"join\", \"kinda\", \"kind\", \"know\", \"later\", \"leave\", \"less\", \"link\", \"live\", \"lol\", \"lolol\", \"long\", \"long-covid\", \"long_covid\", \"longcovid\", \"look\", \"lot\", \"make\", \"many\", \"may\", \"maybe\", \"much\", \"must\", \"need\", \"never\", \"new\", \"next\", \"news\", \"omg\", \"one\", \"ones\", \"people\",  \"ppl\", \"please\", \"post\", \"probably\", \"pretty\", \"quite\", \"read\", \"really\", \"right\", \"say\", \"see\", \"share\", \"shit\", \"show\", \"speak\", \"sorry\", \"sort\", \"sort-of\", \"still\", \"suck\", \"sure\", \"take\", \"talk\", \"tell\", \"thank\", \"thank-you\", \"thanks\", \"think\", \"thing\", \"time\", \"today\", \"try\", \"tweet\", \"twitter\", \"type\", \"uh\", \"uh-huh\", \"um\", \"update\", \"use\", \"vid\", \"via\", \"want\", \"way\", \"well\", \"would\", \"wrong\", \"yeah\", \"yep\",\"even\" ,\"keep\", \"yet\", \"thread\", \"story\", \"watch\", \"listen\", \"write\", \"video\", \"comment\", \"piece\", \"start\", \"stop\", \"let\", \"put\", \"become\", \"seem\", \"great\", \"amazing\", \"interesting\", \"clear\", \"big\", \"huge\", \"point\", \"amp\", \"rt\", \"the\", \"to\", \"is\", \"are\", \"was\", \"were\", \"has\", \"have\", \"had\", \"do\", \"does\", \"did\", \"can\", \"will\", \"just\", \"going\", \"gonna\",  \"covid\", \"long\", \"you\", \"we\", \"your\", \"i\", \"he\", \"she\", \"they\", \"me\", \"us\", \"our\", \"their\", \"my\", \"his\", \"her\", \"them\", \"should\", \"this\", \"that\", \"these\", \"those\", \"some\", \"any\", \"each\", \"other\", \"another\", \"most\", \"something\", \"anything\", \"everything\", \"nothing\", \"way\"\n",
    "}))\n",
    "\n",
    "vectorizer_args = [\n",
    "    {\"ngram_range\": (1, 1), \"min_df\": 5, \"max_df\": 0.95, \"stop_words\": custom_stopwords},\n",
    "    {\"ngram_range\": (1, 2), \"min_df\": 10, \"max_df\": 0.85, \"stop_words\": custom_stopwords},\n",
    "    {\"ngram_range\": (1, 3), \"min_df\": 15, \"max_df\": 0.75, \"stop_words\": custom_stopwords},\n",
    "    {\"ngram_range\": (1, 1), \"min_df\": 5, \"max_df\": 0.95},\n",
    "    {\"ngram_range\": (1, 2), \"min_df\": 10, \"max_df\": 0.85},\n",
    "    {\"ngram_range\": (1, 3), \"min_df\": 15, \"max_df\": 0.75},\n",
    "]\n",
    "\n",
    "# Store results\n",
    "vectorizer_nr_topics_results = []\n",
    "best_coherence_vn = -1\n",
    "best_vectorizer = None\n",
    "skipped = 0\n",
    "\n",
    "# Run grid search for embedding hyperparameter\n",
    "for vect_arg in vectorizer_args:\n",
    "    print(f\"\\nTesting VECTORIZER={vect_arg}\")\n",
    "    vectorizer_model = CountVectorizer(**vect_arg)\n",
    "\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    topics, probs = topic_model.fit_transform(documents)\n",
    "    raw_topics = topic_model.get_topics()\n",
    "\n",
    "    topic_model.update_topics(\n",
    "        documents,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        top_n_words=TOP_DIVERSITY_WORDS_N\n",
    "    )\n",
    "\n",
    "    topic_info_df = topic_model.get_topic_info()\n",
    "    topic_labels = topic_info_df.set_index(\"Topic\")[\"Name\"].to_dict()\n",
    "\n",
    "    topic_word_data = []\n",
    "    topic_words_for_coherence = []\n",
    "\n",
    "    for topic_id, word_list in topic_model.get_topics().items():\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "\n",
    "        topic_label = topic_labels.get(topic_id, f\"Topic {topic_id}\")\n",
    "\n",
    "        # For diversity export, save top 30\n",
    "        for rank, (word, weight) in enumerate(word_list[:TOP_DIVERSITY_WORDS_N], start=1):\n",
    "            topic_word_data.append({\n",
    "                \"topic\": topic_id,\n",
    "                \"topic_label\": topic_label,\n",
    "                \"word_rank\": rank,\n",
    "                \"word\": word,\n",
    "                \"weight\": weight\n",
    "            })\n",
    "\n",
    "        # For coherence, split multi-word expressions\n",
    "        top_words = [token for word, _ in word_list[:TOP_COHERENCE_WORDS_N] for token in word.split()]\n",
    "        cleaned = [w for w in top_words if isinstance(w, str) and w.strip()]\n",
    "        if len(cleaned) >= 2:\n",
    "            topic_words_for_coherence.append(cleaned)\n",
    "        else:\n",
    "            skipped += 1\n",
    "\n",
    "    print(f\"Skipped {skipped} topic(s) due to insufficient valid words.\")\n",
    "    # Compute coherence\n",
    "    coherence_model = models.CoherenceModel(\n",
    "        topics=topic_words_for_coherence,\n",
    "        texts=tokenized_texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v',\n",
    "        topn=TOP_COHERENCE_WORDS_N,\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    valid_topic_info = topic_info[topic_info.Topic != -1]\n",
    "\n",
    "    if not valid_topic_info.empty and \"Count\" in valid_topic_info.columns:\n",
    "        num_topics = len(valid_topic_info)\n",
    "        avg_topic_size = valid_topic_info[\"Count\"].mean()\n",
    "    else:\n",
    "        num_topics = 0\n",
    "        avg_topic_size = 0.0\n",
    "\n",
    "    vectorizer_nr_topics_results.append({\n",
    "        \"embedding_model\": BEST_EMBEDDING,\n",
    "        \"vectorizer_arg\": vect_arg,\n",
    "        \"num_topics\": num_topics,\n",
    "        \"avg_topic_size\": avg_topic_size,\n",
    "        \"coherence_c_v\": coherence_score\n",
    "    })\n",
    "\n",
    "    print(f\"num_topics={num_topics}, avg_topic_size={avg_topic_size:.2f} coherence={coherence_score:.4f}\")\n",
    "\n",
    "    if coherence_score > best_coherence_vn:\n",
    "        best_coherence_vn = coherence_score\n",
    "        best_vectorizer = vect_arg\n",
    "\n",
    "\n",
    "# Summary\n",
    "print(\"\\nBest Vectorizer:\")\n",
    "print(f\"Best Vectorizer Args: {best_vectorizer}\")\n",
    "\n",
    "# Save results\n",
    "df_vect_nr_topics_hyperparameter = pd.DataFrame(vectorizer_nr_topics_results)\n",
    "df_vect_nr_topics_hyperparameter.to_csv(\n",
    "    os.path.join(results_dir, f\"vectorizer_hyperparameter_{date_today}.csv\"), index=False\n",
    ")"
   ],
   "id": "7459476a8342009d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter UMAP & HDBScan",
   "id": "b5628983ad4e9b36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BEST_EMBEDDING = best_embedding_model\n",
    "BEST_VECT_ARG = best_vectorizer\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(BEST_EMBEDDING)\n",
    "\n",
    "# Define hyperparameter search space\n",
    "umap_args = [\n",
    "    None,\n",
    "    {\"n_neighbors\": 15, \"min_dist\": 0.1, \"n_components\": 5, \"metric\": \"cosine\"},\n",
    "    {\"n_neighbors\": 30, \"min_dist\": 0.0, \"n_components\": 10, \"metric\": \"cosine\"},\n",
    "    {\"n_neighbors\": 10, \"min_dist\": 0.25, \"n_components\": 5, \"metric\": \"cosine\"},\n",
    "]\n",
    "\n",
    "hdbscan_args = [\n",
    "    None,\n",
    "    {\"min_cluster_size\": 30, \"min_samples\": 10, \"metric\": \"euclidean\", \"cluster_selection_method\": \"eom\"},\n",
    "    {\"min_cluster_size\": 15, \"min_samples\": 5, \"metric\": \"euclidean\", \"cluster_selection_method\": \"eom\"},\n",
    "    {\"min_cluster_size\": 50, \"min_samples\": 15, \"metric\": \"euclidean\", \"cluster_selection_method\": \"leaf\"},\n",
    "]\n",
    "\n",
    "# Store results\n",
    "umap_hdbscan_results = []\n",
    "best_coherence = -1\n",
    "best_umap_hdbscan = None\n",
    "skipped = 0\n",
    "\n",
    "# Run UMAP+HDBSCAN grid search\n",
    "for umap_arg, hdbscan_arg in itertools.product(umap_args, hdbscan_args):\n",
    "    print(f\"\\nTesting UMAP={umap_arg} | HDBSCAN={hdbscan_arg}\")\n",
    "\n",
    "    umap_model = UMAP(**umap_arg, random_state=42) if umap_arg else None\n",
    "    hdbscan_model = HDBSCAN(**hdbscan_arg) if hdbscan_arg else None\n",
    "    vectorizer_model = CountVectorizer(**BEST_VECT_ARG)\n",
    "\n",
    "    # Initialize BERTopic with fixed embedding and tuned clustering pipeline\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Fit model\n",
    "    topics, probs = topic_model.fit_transform(documents)\n",
    "\n",
    "    topic_model.update_topics(\n",
    "        documents,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        top_n_words=TOP_DIVERSITY_WORDS_N\n",
    "    )\n",
    "\n",
    "    topic_info_df = topic_model.get_topic_info()\n",
    "    topic_labels = topic_info_df.set_index(\"Topic\")[\"Name\"].to_dict()\n",
    "\n",
    "    topic_word_data = []        # For CSV/word export\n",
    "    topic_words_for_coherence = []  # For CoherenceModel\n",
    "\n",
    "    for topic_id, word_list in topic_model.get_topics().items():\n",
    "        if topic_id == -1:\n",
    "            continue\n",
    "\n",
    "        topic_label = topic_labels.get(topic_id, f\"Topic {topic_id}\")\n",
    "\n",
    "        # For diversity export save top 30\n",
    "        for rank, (word, weight) in enumerate(word_list[:TOP_DIVERSITY_WORDS_N], start=1):\n",
    "            topic_word_data.append({\n",
    "                \"topic\": topic_id,\n",
    "                \"topic_label\": topic_label,\n",
    "                \"word_rank\": rank,\n",
    "                \"word\": word,\n",
    "                \"weight\": weight\n",
    "            })\n",
    "\n",
    "        # For coherence split multi-word expressions\n",
    "        top_words = [token for word, _ in word_list[:TOP_COHERENCE_WORDS_N] for token in word.split()]\n",
    "        cleaned = [w for w in top_words if isinstance(w, str) and w.strip()]\n",
    "        if len(cleaned) >= 2:\n",
    "            topic_words_for_coherence.append(cleaned)\n",
    "        else:\n",
    "            skipped += 1\n",
    "\n",
    "    print(f\"Skipped {skipped} topic(s) due to insufficient valid words.\")\n",
    "\n",
    "    # Coherence score\n",
    "    coherence_model = models.CoherenceModel(\n",
    "        topics=topic_words_for_coherence,\n",
    "        texts=tokenized_texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v',\n",
    "        topn=TOP_COHERENCE_WORDS_N,\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "    # Topic statistics\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    num_topics = len(topic_info[topic_info.Topic != -1])\n",
    "    avg_topic_size = topic_info[topic_info.Topic != -1]['Count'].mean()\n",
    "\n",
    "    umap_hdbscan_results.append({\n",
    "        \"embedding_model\": BEST_EMBEDDING,\n",
    "        \"umap_arg\": umap_arg,\n",
    "        \"hdbscan_arg\": hdbscan_arg,\n",
    "        \"num_topics\": num_topics,\n",
    "        \"avg_topic_size\": avg_topic_size,\n",
    "        \"coherence_c_v\": coherence_score\n",
    "    })\n",
    "\n",
    "    print(f\"num_topics={num_topics}, avg_topic_size={avg_topic_size:.2f} coherence={coherence_score:.4f}\")\n",
    "\n",
    "    if coherence_score > best_coherence:\n",
    "        best_coherence = coherence_score\n",
    "        best_umap_hdbscan = (umap_arg, hdbscan_arg)\n",
    "\n",
    "    # Temporary\n",
    "    temp_df_umap_hdbscan_hyperparameter = pd.DataFrame(umap_hdbscan_results)\n",
    "    temp_df_umap_hdbscan_hyperparameter.to_csv(os.path.join(results_dir, f\"hyperparameter_umap_{umap_arg}_hdbscan_{hdbscan_arg}_{date_today}.csv\"), index=False)\n",
    "\n",
    "    # Count documents per topic\n",
    "    topic_counts = Counter(topic_model.topics_)\n",
    "\n",
    "    # Sort by document count (descending)\n",
    "    sorted_counts = sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Create DataFrame\n",
    "    topic_docs_distribution_df = pd.DataFrame(sorted_counts, columns=[\"topic\", \"count\"])\n",
    "\n",
    "    # Calculate percentage\n",
    "    total_docs = sum(topic_counts.values())\n",
    "    topic_docs_distribution_df[\"percentage\"] = (\n",
    "        topic_docs_distribution_df[\"count\"] / total_docs * 100\n",
    "    ).round(2)\n",
    "\n",
    "    topic_docs_distribution_df.to_csv(os.path.join(results_dir, f\"dist_umap_{umap_arg}_hdbscan_{hdbscan_arg}_{date_today}.csv\"), index=False)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nBest UMAP + HDBSCAN Combination (Stage 2):\")\n",
    "print(f\"Best UMAP Args: {best_umap_hdbscan[0]}\")\n",
    "print(f\"Best HDBSCAN Args: {best_umap_hdbscan[1]}\")\n",
    "\n",
    "# Save results\n",
    "df_umap_hdbscan_hyperparameter = pd.DataFrame(umap_hdbscan_results)\n",
    "df_umap_hdbscan_hyperparameter.to_csv(os.path.join(results_dir, f\"umap_hdbscan_hyperparameter_{date_today}.csv\"), index=False)"
   ],
   "id": "319e964133d860ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### View Topic Distributions",
   "id": "1754896b1d7b3c49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fixed_topic_words_list = []\n",
    "for topic in topic_words_list:\n",
    "    split_words = []\n",
    "    for phrase in topic:\n",
    "        split_words.extend(phrase.split())\n",
    "    unique_words = list({w for w in split_words if w})\n",
    "    if len(unique_words) >= 2:\n",
    "        fixed_topic_words_list.append(unique_words[:TOP_COHERENCE_WORDS_N])\n",
    "\n",
    "# Coherence score\n",
    "coherence_model = models.CoherenceModel(\n",
    "    topics=fixed_topic_words_list,\n",
    "    texts=tokenized_texts,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v',\n",
    "    topn=TOP_COHERENCE_WORDS_N,\n",
    ")\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "# Topic statistics\n",
    "topic_info = topic_model.get_topic_info()\n",
    "num_topics = len(topic_info[topic_info.Topic != -1])\n",
    "avg_topic_size = topic_info[topic_info.Topic != -1]['Count'].mean()\n",
    "\n",
    "umap_hdbscan_results.append({\n",
    "    \"embedding_model\": BEST_EMBEDDING,\n",
    "    \"umap_arg\": umap_arg,\n",
    "    \"hdbscan_arg\": hdbscan_arg,\n",
    "    \"num_topics\": num_topics,\n",
    "    \"avg_topic_size\": avg_topic_size,\n",
    "    \"coherence_c_v\": coherence_score\n",
    "})\n",
    "\n",
    "print(f\"num_topics={num_topics}, avg_topic_size={avg_topic_size:.2f} coherence={coherence_score:.4f}\")\n",
    "\n",
    "if coherence_score > best_coherence:\n",
    "    best_coherence = coherence_score\n",
    "    best_umap_hdbscan = (umap_arg, hdbscan_arg)\n",
    "\n",
    "# temp\n",
    "temp_df_umap_hdbscan_hyperparameter = pd.DataFrame(umap_hdbscan_results)\n",
    "temp_df_umap_hdbscan_hyperparameter.to_csv(os.path.join(results_dir, f\"hyperparameter_umap_{umap_arg}_hdbscan_{hdbscan_arg}_{date_today}.csv\"), index=False)\n",
    "\n",
    "# Count documents per topic\n",
    "topic_counts = Counter(topic_model.topics_)\n",
    "\n",
    "# Sort by document count (descending)\n",
    "sorted_counts = sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create DataFrame\n",
    "topic_docs_distribution_df = pd.DataFrame(sorted_counts, columns=[\"topic\", \"count\"])\n",
    "\n",
    "# Calculate percentage\n",
    "total_docs = sum(topic_counts.values())\n",
    "topic_docs_distribution_df[\"percentage\"] = (\n",
    "    topic_docs_distribution_df[\"count\"] / total_docs * 100\n",
    ").round(2)\n",
    "\n",
    "topic_docs_distribution_df.to_csv(os.path.join(results_dir, f\"dist_umap_{umap_arg}_hdbscan_{hdbscan_arg}_{date_today}.csv\"), index=False)"
   ],
   "id": "52824c55dab6947c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reducing Outliers",
   "id": "54b344344fa31a5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "topics, probs = topic_model.fit_transform(documents)\n",
    "\n",
    "embeddings = embedding_model.encode(documents, show_progress_bar=True)\n",
    "\n",
    "new_topics = topic_model.reduce_outliers(\n",
    "            documents=documents,\n",
    "            topics=topics,\n",
    "            strategy=\"embeddings\",\n",
    "            embeddings=embeddings,\n",
    ")"
   ],
   "id": "256625678f5f2c2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### View the new docs distributions results",
   "id": "9ec9ae1e4bd7d076"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Count documents per topic\n",
    "topic_counts = Counter(new_topics)\n",
    "\n",
    "# Sort by document count (descending)\n",
    "sorted_counts = sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create DataFrame\n",
    "topic_docs_distribution_df = pd.DataFrame(sorted_counts, columns=[\"topic\", \"count\"])\n",
    "\n",
    "# Calculate percentage\n",
    "total_docs = sum(topic_counts.values())\n",
    "topic_docs_distribution_df[\"percentage\"] = (\n",
    "    topic_docs_distribution_df[\"count\"] / total_docs * 100\n",
    ").round(2)\n",
    "\n",
    "# View or save\n",
    "topic_docs_distribution_df"
   ],
   "id": "474b5621f2807362",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Update the model to use the new topic",
   "id": "d974e037b68997a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "topic_model.topics_ = new_topics\n",
    "topic_model.update_topics(\n",
    "    documents,\n",
    "    topics=new_topics,\n",
    "    vectorizer_model=CountVectorizer(**BEST_VECT_ARG)\n",
    ")"
   ],
   "id": "64852e5b334ce58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get Coherence and Top Words",
   "id": "f7147836adbf7277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fixed_topic_words_list = []\n",
    "for topic in topic_words_list:\n",
    "    split_words = []\n",
    "    for phrase in topic:\n",
    "        split_words.extend(phrase.split())\n",
    "    unique_words = list({w for w in split_words if w})\n",
    "    if len(unique_words) >= 2:\n",
    "        fixed_topic_words_list.append(unique_words[:TOP_COHERENCE_WORDS_N])\n",
    "\n",
    "# Coherence score\n",
    "coherence_model = models.CoherenceModel(\n",
    "    topics=fixed_topic_words_list,\n",
    "    texts=tokenized_texts,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v',\n",
    "    topn=TOP_COHERENCE_WORDS_N,\n",
    ")\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "coherence_score"
   ],
   "id": "629dd72f2e532d34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Update to 30 words per topic",
   "id": "942348515042fa25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "topic_model.update_topics(documents, top_n_words=30)\n",
    "\n",
    "topic_model.save(os.path.join(results_dir, f\"bertopic_model_{date_today}_30_words\"))"
   ],
   "id": "f1485f33f3861028",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Diversity Score",
   "id": "52ece31dd1871ac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_n_values = [5, 10, 20, 30]\n",
    "diversity_score_results = []\n",
    "for top_n in top_n_values:\n",
    "    diversity_score = topic_diversity(topic_model, top_n=top_n, model_type='bertopic')\n",
    "    diversity_score_results.append({\"top_n\": top_n, \"topic_diversity\": diversity_score})\n",
    "    print(f\"top_n: {top_n} topic_diversity: {diversity_score}\")\n",
    "\n",
    "df_diversity = pd.DataFrame(diversity_score_results)\n",
    "df_diversity.to_csv(os.path.join(results_dir, f\"bertopic_topic_diversity_scores_{date_today}.csv\"), index=False)"
   ],
   "id": "f408d0bc738f1597",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saved all model/config",
   "id": "76c0a2c9ea11d217"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get top N words and weights per topic from BERTopic\n",
    "topic_info_df = topic_model.get_topic_info()\n",
    "topic_labels = topic_info_df.set_index('Topic')['Name'].to_dict()\n",
    "\n",
    "topic_word_data = []\n",
    "for topic_num, word_list in topic_model.get_topics().items():\n",
    "    if topic_num == -1:\n",
    "        continue  # Skip outlier topic\n",
    "    topic_label = topic_labels.get(topic_num, f\"Topic {topic_num}\")\n",
    "    for rank, (word, weight) in enumerate(word_list[:TOP_DIVERSITY_WORDS_N], start=1):\n",
    "        topic_word_data.append({\n",
    "            \"topic\": topic_num,\n",
    "            \"topic_label\": topic_label,\n",
    "            \"word_rank\": rank,\n",
    "            \"word\": word,\n",
    "            \"weight\": weight\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_topic_words = pd.DataFrame(topic_word_data)\n",
    "\n",
    "# Save to CSV\n",
    "topic_words_filename = os.path.join(results_dir, f\"bertopic_top{TOP_DIVERSITY_WORDS_N}_words_per_topic_{date_today}_real30.csv\")\n",
    "df_topic_words.to_csv(topic_words_filename, index=False)\n",
    "\n",
    "print(f\"Top {TOP_DIVERSITY_WORDS_N} words per topic saved to: {topic_words_filename}\")\n",
    "\n",
    "# Print Sample Preview\n",
    "print(f\"\\nTop {TOP_DIVERSITY_WORDS_N} Words per Topic (BERTopic):\")\n",
    "for topic_num in sorted(df_topic_words['topic'].unique()):\n",
    "    topic_label = df_topic_words[df_topic_words['topic'] == topic_num]['topic_label'].iloc[0]\n",
    "    words = df_topic_words[df_topic_words['topic'] == topic_num]['word'].tolist()\n",
    "    print(f\"{topic_label} (Topic {topic_num}): {', '.join(words)}\")\n",
    "\n",
    "\n",
    "num_topics = len(topic_info[topic_info.Topic != -1])\n",
    "avg_topic_size = topic_info[topic_info.Topic != -1]['Count'].mean()\n",
    "\n",
    "print(num_topics, avg_topic_size)\n",
    "\n",
    "summary = [{\"num_topics\": num_topics, \"avg_topic_size\": avg_topic_size, \"coherence_score\": coherence_score, \"emebdding_model\": best_embedding_model, \"best_umap\": best_umap_hdbscan[0], \"best_hdbscan\": best_umap_hdbscan[1], \"best_vectorizer\": best_vectorizer}]\n",
    "df_summary = pd.DataFrame(summary)\n",
    "df_summary.to_csv(os.path.join(results_dir, f\"summary_bertopic_topic_scores_{date_today}.csv\"), index=False)\n",
    "\n",
    "fig = topic_model.visualize_topics()\n",
    "vis_html_path = os.path.join(\n",
    "    results_dir, f\"original_number_topics_visualization_{date_today}.html\"\n",
    ")\n",
    "fig.write_html(vis_html_path)\n",
    "print(f\"ðŸ“Š Saved visualization for original_number topics to: {vis_html_path}\")"
   ],
   "id": "e7b2e09d21196e51",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
